{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceleration Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data load and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Extract Features and Labels\n",
    "Relevant Features for Acceleration:\n",
    "- accelerometerXAxis\n",
    "- accelerometerYAxis\n",
    "- accelerometerZAxis\n",
    "- speedKmh\n",
    "<br></br>\n",
    "- timestamp ?\n",
    "- gyroscope ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.saving import save_model\n",
    "\n",
    "data_bmw = []\n",
    "data_honda = []\n",
    "labels_bmw = []\n",
    "labels_honda = []\n",
    "\n",
    "prepared_data = []\n",
    "prepared_labels = []\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Get the current directory path\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up two directories from the current directory\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir))\n",
    "\n",
    "# Now join the desired directory ('Datasets') to the path that is two levels up\n",
    "datasets_dir = os.path.join(root_dir, 'Datasets')\n",
    "\n",
    "accel_dir = os.path.join(datasets_dir, 'Acceleration')\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for root, dirs, files in os.walk(accel_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            car = os.path.basename(root).split()[0].upper()            \n",
    "            label = os.path.basename(os.path.dirname(root))\n",
    "            # print(f'Processing {car} {label} {file}...')\n",
    "            \n",
    "            file_data = json.load(open(os.path.join(root, file)))\n",
    "            file_data = file_data['capturedData']\n",
    "                                    \n",
    "            # Convert to dataframe\n",
    "            file_data = pd.DataFrame(file_data)           \n",
    "            \n",
    "            # Drop unnecessary columns\n",
    "            file_data = file_data.drop(['id', 'gyroscopeXAxis', 'gyroscopeYAxis', 'gyroscopeZAxis'], axis=1)\n",
    "            \n",
    "            # Rename speed Km/h to speed\n",
    "            file_data.rename(columns={'speed Km/h': 'speed'}, inplace=True)\n",
    "            file_data.rename(columns={'speedKmh': 'speed'}, inplace=True)\n",
    "            \n",
    "            # Drop timestamp\n",
    "            file_data = file_data.drop(['createdAt'], axis=1, errors='ignore')\n",
    "            file_data = file_data.drop(['timestamp'], axis=1, errors='ignore')                    \n",
    "            \n",
    "            if car == 'BMW':\n",
    "                data_bmw.append(file_data.copy())\n",
    "                labels_bmw.append(label)\n",
    "            elif car == 'HONDA':\n",
    "                data_honda.append(file_data.copy())\n",
    "                labels_honda.append(label)            \n",
    "\n",
    "#check for NaNs\n",
    "if data_bmw[0].isnull().values.any() or data_honda[0].isnull().values.any():\n",
    "    print('NaNs in data')\n",
    "else:\n",
    "    print('NO NaNs in data')\n",
    "    \n",
    "# add data_bmw and data_honda to dataset\n",
    "dataset = data_bmw + data_honda\n",
    "dataset_labels = labels_bmw + labels_honda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define window size and overlap\n",
    "window_size = 4\n",
    "overlap = 2\n",
    "\n",
    "# Create sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    for j in range(0, len(dataset[i]) - window_size + 1, overlap):\n",
    "        sequence = dataset[i].iloc[j:j+window_size].values\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "        # Calculate mean of accelerometerYAxis in the current window\n",
    "        mean = np.mean(dataset[i][j:j+window_size]['accelerometerYAxis'])\n",
    "        \n",
    "        # Determine label based on the mean value\n",
    "        if mean > 0.5:\n",
    "            label = 'aggressive'\n",
    "        elif mean > 0.2:\n",
    "            label = 'normal'\n",
    "        else:\n",
    "            label = 'slow'\n",
    "        \n",
    "        labels.append(label)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('Sequences:')\n",
    "print(sequences)\n",
    "print('Labels:')\n",
    "print(labels)\n",
    "\n",
    "# Save sequences and labels to .npy files\n",
    "np.save('saves/sequences.npy', sequences)\n",
    "np.save('saves/labels.npy', labels)\n",
    "\n",
    "# Save dataset and labels to .pkl file\n",
    "# import pickle\n",
    "# with open('dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump((sequences, labels), f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Engineering\n",
    "New Features:\n",
    "- Speed (Calculated by accelerometerY)\n",
    "- Accumulated Acceleration\n",
    "- Distance moved ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Normalize and Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize Each car\n",
    "# concat_data_bmw = pd.concat(data_bmw)\n",
    "# concat_data_honda = pd.concat(data_honda)\n",
    "\n",
    "# print('Concat Data BMW: ')\n",
    "# print(concat_data_bmw.values[1])\n",
    "\n",
    "# # Choose columns to normalize\n",
    "# concat_data_bmw = concat_data_bmw[['accelerometerXAxis', 'accelerometerYAxis', 'accelerometerZAxis', 'speed']]\n",
    "# concat_data_honda = concat_data_honda[['accelerometerXAxis', 'accelerometerYAxis', 'accelerometerZAxis', 'speed']]\n",
    "\n",
    "# # Normalize\n",
    "# scaled_data_bmw = scaler.fit_transform(concat_data_bmw)\n",
    "# print('Scaled Data BMW: ')\n",
    "# print(scaled_data_bmw)\n",
    "\n",
    "# scaled_data_honda = scaler.fit_transform(concat_data_honda)\n",
    "# print('Scaled Data Honda: ')\n",
    "# print(scaled_data_honda)\n",
    "\n",
    "# # Substitute from data_bmw and data_honda to normalized data in prepared_data\n",
    "# for i in range(len(data_bmw)):\n",
    "#     data_bmw[i] = pd.DataFrame(scaled_data_bmw[i*len(data_bmw[i]):(i+1)*len(data_bmw[i])], columns=['accelerometerXAxis', 'accelerometerYAxis', 'accelerometerZAxis', 'speed'])\n",
    "#     prepared_data.append(data_bmw[i])\n",
    "\n",
    "# for i in range(len(data_honda)):\n",
    "#     data_honda[i] = pd.DataFrame(scaled_data_honda[i*len(data_honda[i]):(i+1)*len(data_honda[i])], columns=['accelerometerXAxis', 'accelerometerYAxis', 'accelerometerZAxis', 'speed'])\n",
    "#     prepared_data.append(data_honda[i])\n",
    "\n",
    "\n",
    "\n",
    "# print('Aggregated Data: ')\n",
    "# print(prepared_data)\n",
    "\n",
    "# prepared_labels = labels_bmw + labels_honda\n",
    "# print('Labels: ')\n",
    "# print(prepared_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
