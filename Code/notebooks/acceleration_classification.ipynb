{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceleration Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract Features and Labels\n",
    "Relevant Features for Acceleration:\n",
    "- accelerometerXAxis\n",
    "- accelerometerYAxis\n",
    "- accelerometerZAxis\n",
    "- speedKmh\n",
    "<br></br>\n",
    "- timestamp ?\n",
    "- gyroscope ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "data_bmw = []\n",
    "data_honda = []\n",
    "labels_bmw = []\n",
    "labels_honda = []\n",
    "\n",
    "prepared_data = []\n",
    "prepared_labels = []\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO NaNs in data\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory path\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up two directories from the current directory\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir))\n",
    "\n",
    "# Now join the desired directory ('Datasets') to the path that is two levels up\n",
    "datasets_dir = os.path.join(root_dir, 'Datasets')\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for root, dirs, files in os.walk(datasets_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            car = os.path.basename(root).split()[0].upper()            \n",
    "            label = os.path.basename(os.path.dirname(root))\n",
    "            \n",
    "            file_data = json.load(open(os.path.join(root, file)))\n",
    "            file_data = file_data['capturedData']\n",
    "                                    \n",
    "            # Convert to dataframe\n",
    "            file_data = pd.DataFrame(file_data)           \n",
    "            \n",
    "            # Drop unnecessary columns\n",
    "            file_data = file_data.drop(['id', 'Latitude', 'Longitude', 'gyroscopeXAxis', 'gyroscopeYAxis', 'gyroscopeZAxis'], axis=1)\n",
    "            \n",
    "            # Rename speed Km/h to speed\n",
    "            file_data.rename(columns={'speed Km/h': 'speed'}, inplace=True)\n",
    "            file_data.rename(columns={'speedKmh': 'speed'}, inplace=True)\n",
    "            \n",
    "            # Drop timestamp\n",
    "            file_data = file_data.drop(['createdAt'], axis=1, errors='ignore')\n",
    "            file_data = file_data.drop(['timestamp'], axis=1, errors='ignore')                    \n",
    "            \n",
    "            if car == 'BMW':\n",
    "                data_bmw.append(file_data.copy())\n",
    "                labels_bmw.append(label)\n",
    "            elif car == 'HONDA':\n",
    "                data_honda.append(file_data.copy())\n",
    "                labels_honda.append(label)            \n",
    "\n",
    "#check for NaNs\n",
    "if data_bmw[0].isnull().values.any() or data_honda[0].isnull().values.any():\n",
    "    print('NaNs in data')\n",
    "else:\n",
    "    print('NO NaNs in data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering\n",
    "New Features:\n",
    "- Speed (Calculated by accelerometerY)\n",
    "- Accumulated Acceleration\n",
    "- Distance moved ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Normalize and Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Data BMW: \n",
      "[[0.42432991 0.59656404 0.72300274 0.        ]\n",
      " [0.43609964 0.5425548  0.73695225 0.        ]\n",
      " [0.42231019 0.69527125 0.69672298 0.        ]\n",
      " ...\n",
      " [0.24617761 0.53066339 0.81379612 0.95426202]\n",
      " [0.36474162 0.48877002 0.740912   0.95426202]\n",
      " [0.47802334 0.4854856  0.63905244 0.95426202]]\n",
      "Scaled Data Honda: \n",
      "[[0.74303088 0.44561212 0.51776463 0.        ]\n",
      " [0.80168045 0.49898038 0.52469522 0.        ]\n",
      " [0.80317997 0.50692158 0.47638032 0.00923695]\n",
      " ...\n",
      " [0.76952134 0.38315083 0.60441686 0.93172695]\n",
      " [0.79364197 0.42399552 0.59923704 0.93172695]\n",
      " [0.73517428 0.40522551 0.44928707 0.93172695]]\n",
      "Aggregated Data: \n",
      "[[0.42432991 0.59656404 0.72300274 0.        ]\n",
      " [0.43609964 0.5425548  0.73695225 0.        ]\n",
      " [0.42231019 0.69527125 0.69672298 0.        ]\n",
      " ...\n",
      " [0.76952134 0.38315083 0.60441686 0.93172695]\n",
      " [0.79364197 0.42399552 0.59923704 0.93172695]\n",
      " [0.73517428 0.40522551 0.44928707 0.93172695]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize Each car\n",
    "data_bmw = pd.concat(data_bmw)\n",
    "data_honda = pd.concat(data_honda)\n",
    "\n",
    "# Choose columns to normalize\n",
    "data_bmw = data_bmw[['accelerometerXAxis', 'accelerometerYAxis', 'accelerometerZAxis', 'speed']]\n",
    "data_honda = data_honda[['accelerometerXAxis', 'accelerometerYAxis', 'accelerometerZAxis', 'speed']]\n",
    "\n",
    "# Normalize\n",
    "scaled_data_bmw = scaler.fit_transform(data_bmw)\n",
    "prepared_data.append(scaled_data_bmw)\n",
    "print('Scaled Data BMW: ')\n",
    "print(scaled_data_bmw)\n",
    "\n",
    "scaled_data_honda = scaler.fit_transform(data_honda)\n",
    "prepared_data.append(scaled_data_honda)\n",
    "print('Scaled Data Honda: ')\n",
    "print(scaled_data_honda)\n",
    "\n",
    "# Aggregate all data\n",
    "prepared_data = np.concatenate(prepared_data)\n",
    "print('Aggregated Data: ')\n",
    "print(prepared_data)\n",
    "\n",
    "prepared_labels = labels_bmw + labels_honda\n",
    "\n",
    "# Sequence 4by4\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
