{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Load dos dados do ficheiro JSON e preparação dos dados para treino e teste\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    captured_data = data['capturedData']\n",
    "\n",
    "    accelerometerXAxis = [entry['accelerometerXAxis'] for entry in captured_data]\n",
    "    accelerometerYAxis = [entry['accelerometerYAxis'] for entry in captured_data]\n",
    "    accelerometerZAxis = [entry['accelerometerZAxis'] for entry in captured_data]\n",
    "    gyroscopeXAxis = [entry['gyroscopeXAxis'] for entry in captured_data]\n",
    "    gyroscopeYAxis = [entry['gyroscopeYAxis'] for entry in captured_data]\n",
    "    gyroscopeZAxis = [entry['gyroscopeZAxis'] for entry in captured_data]\n",
    "\n",
    "    # criar dataFrame \n",
    "    df = pd.DataFrame({\n",
    "        'accelerometerXAxis': accelerometerXAxis,\n",
    "        'accelerometerYAxis': accelerometerYAxis,\n",
    "        'accelerometerZAxis': accelerometerZAxis,\n",
    "        'gyroscopeXAxis': gyroscopeXAxis,\n",
    "        'gyroscopeYAxis': gyroscopeYAxis,\n",
    "        'gyroscopeZAxis': gyroscopeZAxis\n",
    "    })\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df.values)\n",
    "\n",
    "    sequence_length = 11\n",
    "    sequences = []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        sequences.append(scaled_data[i:i+sequence_length])\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "\n",
    "    # conjuntos de treino e teste\n",
    "    X = sequences[:, :-1]\n",
    "    y = sequences[:, -1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "#treinar o modelo LSTM\n",
    "def build_and_train_model(X_train, X_test, y_train, y_test):\n",
    "    # construção do LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(X_train.shape[2])) \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "    return model\n",
    "\n",
    "# prever os valores e mostrar a comparação\n",
    "def predict_and_compare(model, X_test, y_test, scaler):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "    y_test_inverse = scaler.inverse_transform(y_test)\n",
    "\n",
    "    comparison_df = pd.DataFrame({'Real': y_test_inverse.flatten(), 'Predicted': y_pred_inverse.flatten()})\n",
    "\n",
    "    difference = np.abs(comparison_df['Real'] - comparison_df['Predicted'])\n",
    "    comparison_df['Absolute Difference'] = difference\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "def classify_acceleration(data):\n",
    "    max_acceleration_0_10= 0.07\n",
    "    \n",
    "    df = pd.DataFrame(data['capturedData'])\n",
    "    \n",
    "    df['createdAt'] = pd.to_datetime(df['createdAt'])\n",
    "\n",
    "    # converte para float\n",
    "    df['speed Km/h'] = df['speed Km/h'].astype(float)\n",
    "    \n",
    "    # calcula a aceleracao com base na mudança de velocidade\n",
    "    df['acceleration'] = df['speed Km/h'].diff() / df['createdAt'].diff().dt.total_seconds()\n",
    "\n",
    "    # critérios para classificação \n",
    "    slow_threshold = 0.06 * max_acceleration_0_10\n",
    "    aggressive_threshold = 0.08 * max_acceleration_0_10\n",
    "\n",
    "    # funcao para classificar a aceleração\n",
    "    def classify(acceleration):\n",
    "        if acceleration >= aggressive_threshold:\n",
    "            return 'aggressive'\n",
    "        elif acceleration >= slow_threshold:\n",
    "            return 'normal'\n",
    "        else:\n",
    "            return 'slow'\n",
    "\n",
    "    # aplicar a função de classificação\n",
    "    df['classification'] = df['acceleration'].apply(classify)\n",
    "\n",
    "    return df[['acceleration', 'classification']]\n",
    "\n",
    "def main():\n",
    "    datasets = [\n",
    "        # BMW e36 datasets 10m\n",
    "        r'..\\Datasets\\Acceleration\\Till reached distance\\10m\\aggressive\\BMW e36\\acceleration 0m 10m aggressive-23-04-2023-19-42-30.json',\n",
    "        r'..\\Datasets\\Acceleration\\Till reached distance\\10m\\normal\\BMW e36\\acceleration 0m 10m normal-23-04-2023-19-30-17.json',\n",
    "        r'..\\Datasets\\Acceleration\\Till reached distance\\10m\\slow\\BMW e36\\acceleration 0m 10m slow-23-04-2023-19-19-20.json',\n",
    "\n",
    "    ]\n",
    "\n",
    "    #comparação dos resultados\n",
    "    models = []\n",
    "    scalers = []\n",
    "    comparison_dfs = []\n",
    "\n",
    "    for dataset in datasets:\n",
    "        print(\"Load e treino do modelo para:\", dataset)\n",
    "        X_train, X_test, y_train, y_test, scaler = load_dataset(dataset)\n",
    "        model = build_and_train_model(X_train, X_test, y_train, y_test)\n",
    "        models.append(model)\n",
    "        scalers.append(scaler)\n",
    "\n",
    "        # Carregamento dos dados específicos para classificação de velocidade\n",
    "        with open(dataset, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        classification_result = classify_speed(data)  # Classificar velocidade para os dados atuais\n",
    "        print(classification_result)\n",
    "\n",
    "        for i, model in enumerate(models):\n",
    "            print(\"\\n\\nResultados para o Dataset:\", datasets[i])\n",
    "            X_train, X_test, y_train, y_test, scaler = load_dataset(datasets[i])\n",
    "            comparison_df = predict_and_compare(model, X_test, y_test, scalers[i])\n",
    "            comparison_dfs.append(comparison_df)\n",
    "            print(comparison_df)  \n",
    "            print(\"\\n-----------------------------\\n\")  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
