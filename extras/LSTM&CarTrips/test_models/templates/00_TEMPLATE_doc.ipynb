{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzTK7gM5ydFL"
      },
      "source": [
        "**IMPORT LIBS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG6VE-z-iIFN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import keras.backend as K\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create aux folders and get file path**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make auxiliar folders\n",
        "if not os.path.exists('runtime_saves'):\n",
        "    os.makedirs('runtime_saves')\n",
        "if not os.path.exists('runtime_saves/models'):\n",
        "    os.makedirs('runtime_saves/models')\n",
        "if not os.path.exists('runtime_saves/train&test'):\n",
        "    os.makedirs('runtime_saves/train&test')\n",
        "    \n",
        "current_dir = os.getcwd()\n",
        "\n",
        "root_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir, os.pardir))\n",
        "\n",
        "datasetUAH_dir = os.path.join(root_dir, 'datasets', 'UAH-DRIVESET-v1', 'UAH-Processed')\n",
        "\n",
        "print(f'Root directory: {root_dir}')\n",
        "print(f'Dataset directory: {datasetUAH_dir}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHBmH_88Ilpx"
      },
      "source": [
        "# **AUX FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0lXdqGfInKu"
      },
      "outputs": [],
      "source": [
        "def save_manovers_positions_to_csv_file(gps_positions, manovers, filename):\n",
        "  output = np.zeros_like(gps_positions)\n",
        "\n",
        "  # Iterate through the elements of arr2\n",
        "  for i in range(len(manovers)):\n",
        "    # Check if the element in arr2 is 1\n",
        "    if manovers[i] == 1:\n",
        "      # Copy the corresponding values from arr1 to the output array\n",
        "      output[i] = gps_positions[i]\n",
        "\n",
        "  output = output[~np.all(output == 0, axis=1)]\n",
        "  \n",
        "  filename = 'runtime_saves/' + filename\n",
        "    \n",
        "  np.savetxt(filename, output, delimiter=',', fmt='%.9f')\n",
        "\n",
        "\n",
        "\n",
        "def separate_positives_negatives(data):\n",
        "  # Ensure the input is converted to a NumPy array for easier manipulation\n",
        "  data = np.array(data)\n",
        "\n",
        "  # Create two empty arrays to store positive and negative values\n",
        "  positives = np.zeros_like(data)\n",
        "  negatives = np.zeros_like(data)\n",
        "\n",
        "  # Use boolean indexing to separate positive and negative values\n",
        "  positives[data > 0] = data[data > 0]\n",
        "  negatives[data < 0] = -data[data < 0]\n",
        "\n",
        "  # Combine the positive and negative values into a single 2D array\n",
        "  return (positives, negatives)\n",
        "\n",
        "def normalize_between_0_and_max(data):\n",
        "  max_value = np.max(data)\n",
        "  return data / max_value\n",
        "\n",
        "def normalize_between_0_and_max_v2(data, max_value):\n",
        "  return data / max_value\n",
        "\n",
        "def split_train_test(data, test_size=0.2):\n",
        "  # Check if test_size is between 0 and 1\n",
        "  if test_size < 0 or test_size > 1:\n",
        "    raise ValueError(\"test_size must be between 0 and 1.\")\n",
        "\n",
        "  # Get the number of samples\n",
        "  num_samples = data.shape[0]\n",
        "\n",
        "  # Calculate the number of samples for each set\n",
        "  train_size = int(num_samples * (1 - test_size))\n",
        "  test_size = num_samples - train_size\n",
        "\n",
        "  # Randomly shuffle the data for better splitting (optional)\n",
        "  #np.random.shuffle(data)\n",
        "\n",
        "  # Split the data into training and test sets\n",
        "  train_data = data[:train_size]\n",
        "  test_data = data[train_size:]\n",
        "\n",
        "  return train_data, test_data\n",
        "\n",
        "def y_classification(data, threshold):\n",
        "  classification = np.zeros_like(data, dtype=int)  # Initialize output array\n",
        "\n",
        "  for col in range(0, 12):  # Loop through each column\n",
        "    max_value = np.max(data[:, col])\n",
        "    threshold_pos = max_value * threshold\n",
        "    classification[:, col] = np.where(data[:, col] >= threshold_pos, 1, 0)\n",
        "\n",
        "  return classification\n",
        "\n",
        "def max_of_vectors(vec1, vec2, vec3, vec4, vec5, vec6):\n",
        "  # Combine all vectors into a single array\n",
        "  all_vectors = np.array([vec1, vec2, vec3, vec4, vec5, vec6])\n",
        "\n",
        "  # Find the maximum value in the array\n",
        "  max_value = np.max(all_vectors)\n",
        "\n",
        "  return max_value\n",
        "\n",
        "def has_one(data):\n",
        "  \"\"\"\n",
        "  This function receives a numpy array and returns a new array\n",
        "  with 1 if the correspondent row of input array has at least one cellule with 1.\n",
        "  In other case the cellule is 0.\n",
        "\n",
        "  Args:\n",
        "      data: A numpy array of shape (n, 12) with 0 or 1 values in each cell.\n",
        "\n",
        "  Returns:\n",
        "      A numpy array of shape (n, 1) with 1s where the corresponding row in data has at least one 1, and 0s otherwise.\n",
        "  \"\"\"\n",
        "  # We sum each row, and any value greater than zero indicates at least one 1 in that row\n",
        "  return np.sum(data, axis=1)[:, np.newaxis] > 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aATQYo4TiWrU"
      },
      "source": [
        "# **DATA PREPROCESSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data structure:**\n",
        "\n",
        "- Acceleration (m/s2): X, Y, Z Axis \n",
        "\n",
        "- Gyroscope (°/s): X, Y, Z Axis\n",
        "\n",
        "- GPS: Latitude and Longitude "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5wPPy3OiYj9"
      },
      "outputs": [],
      "source": [
        "dataset = os.path.join(os.getcwd(), os.pardir, 'docs', 'v2', 'dataset-all.csv')\n",
        "# dataset = os.path.join(os.getcwd(), os.pardir, 'docs', 'v1', 'Abrantes-Leiria.csv')\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "df = pd.read_csv(dataset)\n",
        "\n",
        "acelX = df['accelerometerXAxis']\n",
        "acelY = df['accelerometerYAxis']\n",
        "acelZ = df['accelerometerZAxis']\n",
        "\n",
        "gyrX = df['gyroscopeXAxis']\n",
        "gyrY = df['gyroscopeYAxis']\n",
        "gyrZ = df['gyroscopeZAxis']\n",
        "\n",
        "latitude = df['latitude']\n",
        "longitude = df['longitude']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzW3XSugY8m3",
        "outputId": "809859f8-a9ef-4638-c9be-f3536c2556c9"
      },
      "outputs": [],
      "source": [
        "# print(df['accelerometerXAxis'].describe())\n",
        "# print(df['accelerometerYAxis'].describe())\n",
        "# print(df['accelerometerZAxis'].describe())\n",
        "# print(df['gyroscopeXAxis'].describe())\n",
        "# print(df['gyroscopeYAxis'].describe())\n",
        "# print(df['gyroscopeZAxis'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb3I99C7ASnM"
      },
      "source": [
        "## **Separate data by maneuver**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We identify different manovers based on the **Acceleration and Gyroscope data**.\n",
        "\n",
        "Accelerometer:\n",
        "- X - Curves\n",
        "- Y - Acceleration and braking\n",
        "- Z - Vertical acceleration - Uphill and downhill\n",
        "\n",
        "Gyroscope:\n",
        "- X - Longitudinal tilt - Uphill and downhill\n",
        "- Y - Lateral tilt\n",
        "- Z - Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaJIdH4qvx0t"
      },
      "outputs": [],
      "source": [
        "# Curves\n",
        "turnRightX, turnLeftX = separate_positives_negatives(acelX)\n",
        "# Acceleration and breaking\n",
        "accelY, breakY = separate_positives_negatives(acelY)\n",
        "# Vertical acceleration - hills and bumps\n",
        "positiveZ, negativeZ = separate_positives_negatives(acelZ)\n",
        "\n",
        "# Longitudinal tilt - hills and bumps\n",
        "gyrPositiveX, gyrNegativeX = separate_positives_negatives(gyrX)\n",
        "# Lateral tilt\n",
        "gyrPositiveY, gyrNegativeY = separate_positives_negatives(gyrY)\n",
        "# Curves\n",
        "gyrPositiveZ, gyrNegativeZ = separate_positives_negatives(gyrZ)\n",
        "\n",
        "\n",
        "turnRightX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPIA30JzCcST"
      },
      "source": [
        "# **Normalize Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We normalize the data to guarantee a consistent representation of the data and a better performance of the model.\n",
        "\n",
        "The normalization in done in the following way:\n",
        "- Identify the maximum absolute value of the combined three axis of the accelerometer and gyroscope\n",
        "- Normalize the values between 0 and max value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTCRAhTXZXNL"
      },
      "outputs": [],
      "source": [
        "max_accel = max_of_vectors(turnRightX, turnLeftX, accelY, breakY, positiveZ, negativeZ)\n",
        "max_gyr = max_of_vectors(gyrPositiveX, gyrNegativeX, gyrPositiveY, gyrNegativeY, gyrPositiveZ, gyrNegativeZ)\n",
        "\n",
        "turnRightXn = normalize_between_0_and_max_v2(turnRightX, max_accel)\n",
        "turnLeftXn = normalize_between_0_and_max_v2(turnLeftX, max_accel)\n",
        "accelYn = normalize_between_0_and_max_v2(accelY, max_accel)\n",
        "breakYn = normalize_between_0_and_max_v2(breakY, max_accel)\n",
        "positiveZn = normalize_between_0_and_max_v2(positiveZ, max_accel)\n",
        "negativeZn = normalize_between_0_and_max_v2(negativeZ, max_accel)\n",
        "gyrPositiveXn = normalize_between_0_and_max_v2(gyrPositiveX, max_gyr)\n",
        "gyrNegativeXn = normalize_between_0_and_max_v2(gyrNegativeX, max_gyr)\n",
        "gyrPositiveYn = normalize_between_0_and_max_v2(gyrPositiveY, max_gyr)\n",
        "gyrNegativeYn = normalize_between_0_and_max_v2(gyrNegativeY, max_gyr)\n",
        "gyrPositiveZn = normalize_between_0_and_max_v2(gyrPositiveZ, max_gyr)\n",
        "gyrNegativeZn = normalize_between_0_and_max_v2(gyrNegativeZ, max_gyr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrtvVRZ0Avz8"
      },
      "source": [
        "## Array with all the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppkRUVMX1c7W"
      },
      "outputs": [],
      "source": [
        "x = np.array(list(zip(turnRightXn, turnLeftXn, accelYn, breakYn, positiveZn, negativeZn, gyrPositiveXn, gyrNegativeXn, gyrPositiveYn, gyrNegativeYn, gyrPositiveZn, gyrNegativeZn)))\n",
        "\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Labelling Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The labelling is done considering:\n",
        "- The **Max value** of each column\n",
        "- An **Adjustable threshold** between 0 and 1.\n",
        "\n",
        "The product of this maximum value and the threshold establishes a reference point that indicates the intensity of the maneuver.\n",
        "\n",
        "- If the data value is greater than or equal to the reference point, it will be classified as 1 (aggressive).\n",
        "\n",
        "- If the data value is less than the reference point, it will be classified as 0 (non-aggressive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJVtNOyF3bU5",
        "outputId": "a8fca71e-9321-4b0d-d334-51b8ba23f123"
      },
      "outputs": [],
      "source": [
        "y = y_classification(x, 0.3)\n",
        "print (np.sum(y, axis=0))\n",
        "\n",
        "filename = 'runtime_saves/' + 'Y.csv'\n",
        "print(y)\n",
        "\n",
        "np.savetxt(filename, y, delimiter=',', fmt='%.0i')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IZvV0MhdLBy"
      },
      "source": [
        "## Show manovers on Google Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvW2QnkTdRiA"
      },
      "outputs": [],
      "source": [
        "positions = np.array(list(zip(latitude, longitude)))\n",
        "manover_accelY = y[:, 2]\n",
        "manover_breakY = y[:, 3]\n",
        "manover_turnRightXn = y[:, 0]\n",
        "manover_turnLeftXn = y[:, 1]\n",
        "gyrPositiveZn = y[:, 10]\n",
        "gyrNegativeZn = y[:, 11]\n",
        "save_manovers_positions_to_csv_file(positions, manover_accelY, \"accelY.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, manover_breakY, \"breakY.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, manover_turnRightXn, \"turnRightX.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, manover_turnLeftXn, \"turnLeftX.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, gyrPositiveZn, \"gyrPositZ.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, gyrNegativeZn, \"gyrNegZ.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_78VHvBRJQ"
      },
      "source": [
        "## Plot manovers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cksFepBiioYu"
      },
      "outputs": [],
      "source": [
        "plt.plot(y[:, 2], marker='.', linestyle='none')\n",
        "plt.plot(y[:, 3], marker='.', linestyle='none')\n",
        "\n",
        "plt.legend(['Accel Y', 'Break Y'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB-CdF_MGToJ"
      },
      "source": [
        "## Separate data in train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd56BA3fIORH"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = split_train_test(x, test_size=0.2)\n",
        "\n",
        "y_train, y_test = split_train_test(y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d5xKgrEC-ks"
      },
      "source": [
        "## Create the input tensor data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOkN2T88doeE"
      },
      "outputs": [],
      "source": [
        "train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
        "test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "np.savetxt(\"runtime_saves/train&test/x_train.csv\", x_train, delimiter=',', fmt='%.9f')\n",
        "np.savetxt(\"runtime_saves/train&test/x_test.csv\", x_test, delimiter=',', fmt='%.9f')\n",
        "np.savetxt(\"runtime_saves/train&test/y_train.csv\", y_train, delimiter=',', fmt='%.0i')\n",
        "np.savetxt(\"runtime_saves/train&test/y_test.csv\", y_test, delimiter=',', fmt='%.0i')\n",
        "\n",
        "np.savetxt(\"runtime_saves/train&test/train.csv\", train.reshape(train.shape[0], train.shape[2]), delimiter=',', fmt='%.9f')\n",
        "np.savetxt(\"runtime_saves/train&test/test.csv\", test.reshape(test.shape[0], test.shape[2]), delimiter=',', fmt='%.9f')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBfgiQgAGZPW"
      },
      "source": [
        "## **Create Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### #TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wdxfd2JJwmh"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "\n",
        "dropout = 0.01\n",
        "# learning_rate = 0.001\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(50, input_shape=(1, train.shape[2]), return_sequences=True))\n",
        "model_lstm.add(Dropout(dropout))\n",
        "model_lstm.add(Dense(32,activation='relu'))        \n",
        "model_lstm.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khawMeLUGczr"
      },
      "source": [
        "## **Train Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### #TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNkg4Mr-K36t",
        "outputId": "c5ced2dc-cc07-4cc5-d922-f176e6e16542"
      },
      "outputs": [],
      "source": [
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Train the model\n",
        "model_lstm_output = model_lstm.fit(train, y_train, epochs=30, batch_size=32, validation_split=0.2, shuffle=True, callbacks=[early_stopping, reduce_lr])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct_S460uGhxP"
      },
      "source": [
        "# **RESULTS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = model_lstm.predict(test)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = np.round(pred).astype(int)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = np.argmax(pred, axis=1)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conf_mat = metrics.confusion_matrix(y_test, pred)\n",
        "conf_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Accuracy = $\\large = \\frac{Correct~Predictions}{All~Predictions}$\n",
        "- Precision for a given class = $\\large = \\frac{Correct~Predictions~for~the~Class}{All~Predictions~for~the~Class}$   \n",
        "- Recall for a given class = $\\large = \\frac{Correct~Predictions~for~the~Class}{All~Instances~of~the~Class}$  \n",
        "\n",
        "- Averaging is a way to get a single number for multiclass. Depending on the importance one wants to give to minority classes: \n",
        "    - Macro average: Compute the metric for each class, and returns the average without considering the proportion for each class in the dataset. For instance:\n",
        "\n",
        "        Precision = $\\large = \\frac{P_{class 1} ~+~ P_{class 2} ~+~ ... ~+~ P_{class n}}{N}$   \n",
        "    \n",
        "    - Weighted average: Compute the metric for each class, and returns the average considering the proportion (weighted) for each class in the dataset. For instance:\n",
        "\n",
        "        Precision = $\\large = \\frac{N_1 ~*~ P_{class 1} ~+~ N_2 ~*~ P_{class 2} ~+~ ... ~+~ N_n ~*~ P_{class n}}{N}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculates performance metrics\n",
        "acc = accuracy_score(y_true =  y_test, y_pred = pred)\n",
        "print(f'Accuracy : {np.round(acc*100,2)}%')\n",
        "          \n",
        "precision = precision_score(y_true =  y_test, y_pred = pred, average='macro')\n",
        "print(f'Precision - Macro: {np.round(precision*100,2)}%')\n",
        "\n",
        "recall = recall_score(y_true =  y_test, y_pred = pred, average='macro')\n",
        "print(f'Recall - Macro: {np.round(recall*100,2)}%')\n",
        "\n",
        "f1 = f1_score(y_true =  y_test, y_pred = pred, average='macro')\n",
        "print(f'F1-score - Macro: {np.round(f1*100,2)}%')\n",
        "\n",
        "precision = precision_score(y_true =  y_test, y_pred = pred, average='weighted')\n",
        "print(f'Precision - Weighted: {np.round(precision*100,2)}%')\n",
        "\n",
        "recall = recall_score(y_true =  y_test, y_pred = pred, average='weighted')\n",
        "print(f'Recall - Weighted: {np.round(recall*100,2)}%')\n",
        "\n",
        "f1 = f1_score(y_true =  y_test, y_pred = pred, average='weighted')\n",
        "print(f'F1-score - Weighted: {np.round(f1*100,2)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "clabels = ['AccelY', 'BreakY', 'TurnRightX', 'Turn LeftX', 'PositiveZ', 'NegativeZ', 'GyrPositiveX', 'GyrNegativeX', 'GyrPositiveY', 'GyrNegativeY', 'GyrPositiveZ', 'GyrNegativeZ']\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = clabels)\n",
        " \n",
        "# display matrix\n",
        "cm_display.plot()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5yRYVkqpv51"
      },
      "source": [
        "# **TEST THE NETWORK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLflDJutrQ0h"
      },
      "outputs": [],
      "source": [
        "plt.plot(model_lstm_output.history['loss'])\n",
        "plt.plot(model_lstm_output.history['val_loss'])\n",
        "plt.title('Historico de train')\n",
        "plt.xlabel('Epocas de train')\n",
        "plt.ylabel('Função custo')\n",
        "plt.legend(['Erro train', 'Erro test'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTtErVAPKNQT"
      },
      "outputs": [],
      "source": [
        "accuracy = model_lstm.evaluate(test, y_test)[1]  # Assuming accuracy is the second metric\n",
        "print('Test Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTRP1HLnH5VA",
        "outputId": "16236fd5-cb67-4cc2-8018-fe7b9b86945e"
      },
      "outputs": [],
      "source": [
        "loss, accurary = model_lstm.evaluate(test, y_test, batch_size=16)\n",
        "print('Test loss/accurary:', loss, accurary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLTGBDbnb5kg"
      },
      "outputs": [],
      "source": [
        "test[0]\n",
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCXg55GxwbGg"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for i in range(100):\n",
        "    a = x_test[i]\n",
        "    b = a.reshape(1, 1, 12)\n",
        "\n",
        "    # Make predictions on new data\n",
        "    prediction = model_lstm.predict(b)\n",
        "    #predicted_class = label_encoder.inverse_transform(prediction)[0]\n",
        "\n",
        "    np.round(prediction, decimals=1, out=prediction)\n",
        "    np.round(x_test[i], decimals=1, out=x_test[i])\n",
        "    #print(\"Value:\", newArray[i + start])\n",
        "    if (np.sum(y_test[i]) > 0):\n",
        "      print(\"X [:\", x_test[i])\n",
        "      print(\"Y [:\", y_test[i])\n",
        "      print(\"PC:\", prediction)\n",
        "      print (i)\n",
        "    i = 1 + 1\n",
        "#PREDICTIONS WITH COLAB MODEL\n",
        "#prediction = model.predict(teste)\n",
        "#print(\"Predicted class:\", prediction)\n",
        "#print(\"Predicted class:\", predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmrX4Kzdc0T3",
        "outputId": "3c468fe8-622f-476e-f75c-750a4878ea26"
      },
      "outputs": [],
      "source": [
        "test_value = np.array([0., 0.363, 0.313, 0., 0., 0.31, 0.393, 0., 0., 0.244, 0.247, 0.])\n",
        "test_value = test_value.reshape(1, 1, 12)\n",
        "\n",
        "# Make predictions on new data\n",
        "prediction = model_lstm.predict(test_value)\n",
        "np.round(prediction, decimals=2, out=prediction)\n",
        "\n",
        "print(\"Value    :\", test_value[0][0])\n",
        "print(\"Predicted:\", prediction[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02BdeK0gJrOU"
      },
      "source": [
        "# **SAVE THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "KGOyK8rXJvmx",
        "outputId": "7d0a5249-f640-4945-b90c-feaa6b10b3ee"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "model_name = 'lstm_model_' + datetime.datetime.now().strftime(\"%Y-%m-%d %HH%Mm%Ss\") + '.h5'\n",
        "\n",
        "# Save the model in runtime_saves/models folder\n",
        "model_lstm.save(os.path.join(\".\", 'runtime_saves', 'models', model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model sumary\n",
        "model_lstm.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
