overfitting
	cross validation data so the model doesnt train only for the training dataset, and cant genezalize for 
	
	
Model:
	Input Layer: For time-series data, this is a sequence of values per time step.
		input_layer = Input(shape=(timesteps, features))

	LSTM Layers: Designed to capture long-term dependencies and patterns in the sequence data.
		Stack multiple LSTM layers to increase the model's capacity to learn complex temporal relationships.
		Adding return_sequences=True allows the layer to return the full sequence of outputs for each input sequence, which is necessary when stacking LSTM layers.
		
		How many units and why?

	Dropout Layer (Optional):
		Prevents overfitting by randomly setting a fraction of input units to 0 at each update during training time.
		Normally added after LSTM layers.

	Dense Layer:
		Acts as a fully connected layer that combines the features learned by the LSTM layers to make a prediction.
		!!!
		For binary classification, the output layer usually has one unit with a sigmoid activation function. For multi-class classification, the output layer will have as many units as there are classes, with a softmax activation function.

	Output Layer:
		Final layer that provides the classification output.
		!!
		For binary classification, use one unit with a sigmoid activation. For multi-class classification, use units=num_classes with a softmax activation.


Compile Model:

	Mean Square Error vs categorical crossentropyentropy vs binary crossentropy