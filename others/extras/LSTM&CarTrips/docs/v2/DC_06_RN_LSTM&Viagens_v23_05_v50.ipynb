{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzTK7gM5ydFL"
      },
      "source": [
        "# **IMPORT LIBS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HG6VE-z-iIFN"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from skimage.transform import rotate, shear, zoom\n",
        "#from imgaug import augmenters as iaa\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYSWggNH_f5x"
      },
      "source": [
        "#**LOAD THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BrvyPeh_SAC"
      },
      "outputs": [],
      "source": [
        "#model_lstm = tf.keras.models.load_model('./lstm_model_v40.h5')\n",
        "\n",
        "# (Optional) Print a summary of the model architecture\n",
        "#model_lstm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHBmH_88Ilpx"
      },
      "source": [
        "# **AUX FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F0lXdqGfInKu"
      },
      "outputs": [],
      "source": [
        "def save_manovers_positions_to_csv_file(gps_positions, manovers, filename):\n",
        "  output = np.zeros_like(gps_positions)\n",
        "\n",
        "  # Iterate through the elements of arr2\n",
        "  for i in range(len(manovers)):\n",
        "    # Check if the element in arr2 is 1\n",
        "    if manovers[i] == 1:\n",
        "      # Copy the corresponding values from arr1 to the output array\n",
        "      output[i] = gps_positions[i]\n",
        "\n",
        "  output = output[~np.all(output == 0, axis=1)]\n",
        "  np.savetxt(filename, output, delimiter=',', fmt='%.9f')\n",
        "\n",
        "\n",
        "\n",
        "def separate_positives_negatives(data):\n",
        "  # Ensure the input is converted to a NumPy array for easier manipulation\n",
        "  data = np.array(data)\n",
        "\n",
        "  # Create two empty arrays to store positive and negative values\n",
        "  positives = np.zeros_like(data)\n",
        "  negatives = np.zeros_like(data)\n",
        "\n",
        "  # Use boolean indexing to separate positive and negative values\n",
        "  positives[data > 0] = data[data > 0]\n",
        "  negatives[data < 0] = -data[data < 0]\n",
        "\n",
        "  # Combine the positive and negative values into a single 2D array\n",
        "  return (positives, negatives)\n",
        "\n",
        "def normalize_between_0_and_max(data):\n",
        "  max_value = np.max(data)\n",
        "  return data / max_value\n",
        "\n",
        "def normalize_between_0_and_max_v2(data, max_value):\n",
        "  return data / max_value\n",
        "\n",
        "def split_train_test(data, test_size=0.2):\n",
        "  # Check if test_size is between 0 and 1\n",
        "  if test_size < 0 or test_size > 1:\n",
        "    raise ValueError(\"test_size must be between 0 and 1.\")\n",
        "\n",
        "  # Get the number of samples\n",
        "  num_samples = data.shape[0]\n",
        "\n",
        "  # Calculate the number of samples for each set\n",
        "  train_size = int(num_samples * (1 - test_size))\n",
        "  test_size = num_samples - train_size\n",
        "\n",
        "  # Randomly shuffle the data for better splitting (optional)\n",
        "  #np.random.shuffle(data)\n",
        "\n",
        "  # Split the data into training and test sets\n",
        "  train_data = data[:train_size]\n",
        "  test_data = data[train_size:]\n",
        "\n",
        "  return train_data, test_data\n",
        "\n",
        "def y_classification(data, threshold):\n",
        "  classification = np.zeros_like(data, dtype=int)  # Initialize output array\n",
        "\n",
        "  for col in range(0, 12):  # Loop through each column\n",
        "    max_value = np.max(data[:, col])\n",
        "    threshold_pos = max_value * threshold\n",
        "    classification[:, col] = np.where(data[:, col] >= threshold_pos, 1, 0)\n",
        "\n",
        "  return classification\n",
        "\n",
        "def max_of_vectors(vec1, vec2, vec3, vec4, vec5, vec6):\n",
        "  # Combine all vectors into a single array\n",
        "  all_vectors = np.array([vec1, vec2, vec3, vec4, vec5, vec6])\n",
        "\n",
        "  # Find the maximum value in the array\n",
        "  max_value = np.max(all_vectors)\n",
        "\n",
        "  return max_value\n",
        "\n",
        "def has_one(data):\n",
        "  \"\"\"\n",
        "  This function receives a numpy array and returns a new array\n",
        "  with 1 if the correspondent row of input array has at least one cellule with 1.\n",
        "  In other case the cellule is 0.\n",
        "\n",
        "  Args:\n",
        "      data: A numpy array of shape (n, 12) with 0 or 1 values in each cell.\n",
        "\n",
        "  Returns:\n",
        "      A numpy array of shape (n, 1) with 1s where the corresponding row in data has at least one 1, and 0s otherwise.\n",
        "  \"\"\"\n",
        "  # We sum each row, and any value greater than zero indicates at least one 1 in that row\n",
        "  return np.sum(data, axis=1)[:, np.newaxis] > 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aATQYo4TiWrU"
      },
      "source": [
        "# **IMPORT DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "B5wPPy3OiYj9"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv('Dataset-viagens-longas.csv')\n",
        "#df = pd.read_csv('Abrantes-Leiria.csv')\n",
        "df = pd.read_csv('dataset-all.csv')\n",
        "\n",
        "acelX = df['accelerometerXAxis']\n",
        "acelY = df['accelerometerYAxis']\n",
        "acelZ = df['accelerometerZAxis']\n",
        "\n",
        "gyrX = df['gyroscopeXAxis']\n",
        "gyrY = df['gyroscopeYAxis']\n",
        "gyrZ = df['gyroscopeZAxis']\n",
        "\n",
        "latitude = df['latitude']\n",
        "longitude = df['longitude']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZzW3XSugY8m3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809859f8-a9ef-4638-c9be-f3536c2556c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    150070.000000\n",
            "mean          0.001342\n",
            "std           1.264318\n",
            "min         -11.536232\n",
            "25%          -0.547894\n",
            "50%           0.005779\n",
            "75%           0.559436\n",
            "max          14.109398\n",
            "Name: accelerometerXAxis, dtype: float64\n",
            "count    150070.000000\n",
            "mean          0.055583\n",
            "std           0.932284\n",
            "min         -13.825549\n",
            "25%          -0.397755\n",
            "50%           0.042851\n",
            "75%           0.495079\n",
            "max          11.939904\n",
            "Name: accelerometerYAxis, dtype: float64\n",
            "count    150046.000000\n",
            "mean          0.087325\n",
            "std           1.411255\n",
            "min         -20.017138\n",
            "25%          -0.612250\n",
            "50%           0.050575\n",
            "75%           0.742957\n",
            "max          16.155849\n",
            "Name: accelerometerZAxis, dtype: float64\n",
            "count    150070.000000\n",
            "mean          0.000406\n",
            "std           0.099782\n",
            "min          -2.247918\n",
            "25%          -0.040928\n",
            "50%          -0.000305\n",
            "75%           0.040317\n",
            "max           2.192789\n",
            "Name: gyroscopeXAxis, dtype: float64\n",
            "count    150070.000000\n",
            "mean          0.004894\n",
            "std           0.172807\n",
            "min          -2.713842\n",
            "25%          -0.050702\n",
            "50%           0.000534\n",
            "75%           0.053756\n",
            "max           4.168116\n",
            "Name: gyroscopeYAxis, dtype: float64\n",
            "count    150070.000000\n",
            "mean          0.002314\n",
            "std           0.068646\n",
            "min          -2.660011\n",
            "25%          -0.016798\n",
            "50%          -0.000916\n",
            "75%           0.015272\n",
            "max           2.080317\n",
            "Name: gyroscopeZAxis, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(df['accelerometerXAxis'].describe())\n",
        "print(df['accelerometerYAxis'].describe())\n",
        "print(df['accelerometerZAxis'].describe())\n",
        "print(df['gyroscopeXAxis'].describe())\n",
        "print(df['gyroscopeYAxis'].describe())\n",
        "print(df['gyroscopeZAxis'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb3I99C7ASnM"
      },
      "source": [
        "# **SEPARATE DATA BY MANOVER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "IaJIdH4qvx0t"
      },
      "outputs": [],
      "source": [
        "turnRightX, turnLeftX = separate_positives_negatives(acelX)\n",
        "\n",
        "accelY, breakY = separate_positives_negatives(acelY)\n",
        "\n",
        "positiveZ, negativeZ = separate_positives_negatives(acelZ)\n",
        "\n",
        "gyrPositiveX, gyrNegativeX = separate_positives_negatives(gyrX)\n",
        "gyrPositiveY, gyrNegativeY = separate_positives_negatives(gyrY)\n",
        "gyrPositiveZ, gyrNegativeZ = separate_positives_negatives(gyrZ)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "turnRightX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHxP7SVfGrX6",
        "outputId": "462b33e6-f35f-4fe1-bc33-f89dcfe106b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150070,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N01_nop2Znt5"
      },
      "source": [
        "# **CLASSIFICATION BASED ON NOT NORMALIZED VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELrWyhmuZnHS"
      },
      "outputs": [],
      "source": [
        "#newArray1 = np.array(list(zip(turnRightX, turnLeftX, accelY, breakY, positiveZ, negativeZ, gyrPositiveX, gyrNegativeX, gyrPositiveY, gyrNegativeY, gyrPositiveZ, gyrNegativeZ)))\n",
        "\n",
        "#y = y_classification(newArray1, 0.25)\n",
        "#print (np.sum(y, axis=0))\n",
        "#np.savetxt(\"Y.csv\", y, delimiter=',', fmt='%.0i')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPIA30JzCcST"
      },
      "source": [
        "# **NORMALIZE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bTCRAhTXZXNL"
      },
      "outputs": [],
      "source": [
        "max_accel = max_of_vectors(turnRightX, turnLeftX, accelY, breakY, positiveZ, negativeZ)\n",
        "max_gyr = max_of_vectors(gyrPositiveX, gyrNegativeX, gyrPositiveY, gyrNegativeY, gyrPositiveZ, gyrNegativeZ)\n",
        "\n",
        "turnRightXn = normalize_between_0_and_max_v2(turnRightX, max_accel)\n",
        "turnLeftXn = normalize_between_0_and_max_v2(turnLeftX, max_accel)\n",
        "accelYn = normalize_between_0_and_max_v2(accelY, max_accel)\n",
        "breakYn = normalize_between_0_and_max_v2(breakY, max_accel)\n",
        "positiveZn = normalize_between_0_and_max_v2(positiveZ, max_accel)\n",
        "negativeZn = normalize_between_0_and_max_v2(negativeZ, max_accel)\n",
        "gyrPositiveXn = normalize_between_0_and_max_v2(gyrPositiveX, max_gyr)\n",
        "gyrNegativeXn = normalize_between_0_and_max_v2(gyrNegativeX, max_gyr)\n",
        "gyrPositiveYn = normalize_between_0_and_max_v2(gyrPositiveY, max_gyr)\n",
        "gyrNegativeYn = normalize_between_0_and_max_v2(gyrNegativeY, max_gyr)\n",
        "gyrPositiveZn = normalize_between_0_and_max_v2(gyrPositiveZ, max_gyr)\n",
        "gyrNegativeZn = normalize_between_0_and_max_v2(gyrNegativeZ, max_gyr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrtvVRZ0Avz8"
      },
      "source": [
        "# **CREATE AN ARRAY WITH ALL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ppkRUVMX1c7W"
      },
      "outputs": [],
      "source": [
        "newArray = np.array(list(zip(turnRightXn, turnLeftXn, accelYn, breakYn, positiveZn, negativeZn, gyrPositiveXn, gyrNegativeXn, gyrPositiveYn, gyrNegativeYn, gyrPositiveZn, gyrNegativeZn)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX4JSKAddzy0"
      },
      "outputs": [],
      "source": [
        "newArray.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJVtNOyF3bU5",
        "outputId": "a8fca71e-9321-4b0d-d334-51b8ba23f123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 789 2127  408  247  896  191   45   30   10  142   88    6]\n"
          ]
        }
      ],
      "source": [
        "y = y_classification(newArray, 0.3)\n",
        "print (np.sum(y, axis=0))\n",
        "np.savetxt(\"Y.csv\", y, delimiter=',', fmt='%.0i')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IZvV0MhdLBy"
      },
      "source": [
        "# **SHOW MANOVERS ON GOOLGE MAP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvW2QnkTdRiA"
      },
      "outputs": [],
      "source": [
        "positions = np.array(list(zip(latitude, longitude)))\n",
        "manover_accelY = y[:, 2]\n",
        "manover_breakY = y[:, 3]\n",
        "manover_turnRightXn = y[:, 0]\n",
        "manover_turnLeftXn = y[:, 1]\n",
        "gyrPositiveZn = y[:, 10]\n",
        "gyrNegativeZn = y[:, 11]\n",
        "save_manovers_positions_to_csv_file(positions, manover_accelY, \"accelY.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, manover_breakY, \"breakY.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, manover_turnRightXn, \"turnRightX.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, manover_turnLeftXn, \"turnLeftX.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, gyrPositiveZn, \"gyrPositZ.csv\")\n",
        "save_manovers_positions_to_csv_file(positions, gyrNegativeZn, \"gyrNegZ.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_78VHvBRJQ"
      },
      "source": [
        "# **PLOT MANOVERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cksFepBiioYu"
      },
      "outputs": [],
      "source": [
        "plt.plot(y[:, 2], marker='.', linestyle='none')\n",
        "plt.plot(y[:, 3], marker='.', linestyle='none')\n",
        "\n",
        "plt.legend(['Accel Y', 'Break Y'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB-CdF_MGToJ"
      },
      "source": [
        "# **SEPARATE DATA IN TRAIN AND TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Bd56BA3fIORH"
      },
      "outputs": [],
      "source": [
        "x_treino, x_teste = split_train_test(newArray, test_size=0.2)\n",
        "\n",
        "y_treino, y_teste = split_train_test(y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d5xKgrEC-ks"
      },
      "source": [
        "# **CREATE THE INPUT TENSORES DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "EOkN2T88doeE"
      },
      "outputs": [],
      "source": [
        "treino = x_treino.reshape(x_treino.shape[0], 1, x_treino.shape[1])\n",
        "teste = x_teste.reshape(x_teste.shape[0], 1, x_teste.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBfgiQgAGZPW"
      },
      "source": [
        "# **CREATE THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nz1_4zWXY59B"
      },
      "outputs": [],
      "source": [
        "#K.clear_session()\n",
        "\n",
        "#model_lstm = Sequential()\n",
        "#model_lstm.add(LSTM(100, input_shape=(1, treino.shape[2]), activation='relu', return_sequences=True))\n",
        "#model_lstm.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "#model_lstm.add(LSTM(100, activation='sigmoid'))\n",
        "#model_lstm.add(Dense(y_treino.shape[1], activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(50, input_shape=(1, treino.shape[2]), return_sequences=True))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(50))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Dense(y_treino.shape[1], activation='sigmoid'))"
      ],
      "metadata": {
        "id": "4wdxfd2JJwmh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veTKT-DNBhx1"
      },
      "source": [
        "# **COMPILE THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7uASYbH8al-r"
      },
      "outputs": [],
      "source": [
        "model_lstm.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "#model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khawMeLUGczr"
      },
      "source": [
        "# **TRAIN THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SclTSQieaecy"
      },
      "outputs": [],
      "source": [
        "#model_lstm_output = model_lstm.fit(treino, y_treino, epochs=10, batch_size=4, verbose=1, shuffle=False, callbacks=[early_stop], validation_data=(teste, y_teste))\n",
        "#model_lstm_output = model_lstm.fit(treino, y_treino, epochs=3, batch_size=8, verbose=1, shuffle=False, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Train the model\n",
        "model_lstm_output = model_lstm.fit(treino, y_treino, epochs=9, batch_size=32, validation_split=0.2, shuffle=True, callbacks=[early_stopping, reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNkg4Mr-K36t",
        "outputId": "c5ced2dc-cc07-4cc5-d922-f176e6e16542"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "3002/3002 [==============================] - 28s 8ms/step - loss: 0.0093 - accuracy: 0.2080 - val_loss: 0.0038 - val_accuracy: 0.0244 - lr: 0.0010\n",
            "Epoch 2/9\n",
            "3002/3002 [==============================] - 20s 7ms/step - loss: 0.0029 - accuracy: 0.0668 - val_loss: 0.0038 - val_accuracy: 0.0244 - lr: 0.0010\n",
            "Epoch 3/9\n",
            "3002/3002 [==============================] - 22s 7ms/step - loss: 0.0024 - accuracy: 0.0137 - val_loss: 0.0020 - val_accuracy: 0.0289 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "3002/3002 [==============================] - 21s 7ms/step - loss: 0.0019 - accuracy: 0.0189 - val_loss: 0.0019 - val_accuracy: 0.0292 - lr: 0.0010\n",
            "Epoch 5/9\n",
            "3002/3002 [==============================] - 19s 6ms/step - loss: 0.0019 - accuracy: 0.0192 - val_loss: 0.0019 - val_accuracy: 0.0293 - lr: 0.0010\n",
            "Epoch 6/9\n",
            "3002/3002 [==============================] - 20s 7ms/step - loss: 0.0015 - accuracy: 0.2593 - val_loss: 0.0015 - val_accuracy: 0.9292 - lr: 0.0010\n",
            "Epoch 7/9\n",
            "3002/3002 [==============================] - 23s 8ms/step - loss: 0.0013 - accuracy: 0.9433 - val_loss: 0.0016 - val_accuracy: 0.9751 - lr: 0.0010\n",
            "Epoch 8/9\n",
            "3002/3002 [==============================] - 21s 7ms/step - loss: 0.0013 - accuracy: 0.9840 - val_loss: 9.4817e-04 - val_accuracy: 0.9841 - lr: 0.0010\n",
            "Epoch 9/9\n",
            "3002/3002 [==============================] - 21s 7ms/step - loss: 9.4596e-04 - accuracy: 0.9623 - val_loss: 8.4673e-04 - val_accuracy: 0.9732 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct_S460uGhxP"
      },
      "source": [
        "# **SHOW THE RESULTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLflDJutrQ0h"
      },
      "outputs": [],
      "source": [
        "plt.plot(model_lstm_output.history['loss'])\n",
        "plt.plot(model_lstm_output.history['val_loss'])\n",
        "plt.title('Historico de treino')\n",
        "plt.xlabel('Epocas de treino')\n",
        "plt.ylabel('Função custo')\n",
        "plt.legend(['Erro treino', 'Erro teste'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTtErVAPKNQT"
      },
      "outputs": [],
      "source": [
        "#accuracy = model_lstm.evaluate(teste, y_teste)[1]  # Assuming accuracy is the second metric\n",
        "#print('Test Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5yRYVkqpv51"
      },
      "source": [
        "# **TEST THE NETWORK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RTRP1HLnH5VA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16236fd5-cb67-4cc2-8018-fe7b9b86945e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1876/1876 [==============================] - 4s 2ms/step - loss: 3.8539e-04 - accuracy: 0.9841\n",
            "Test loss/accurary: 0.0003853856469504535 0.9840741157531738\n"
          ]
        }
      ],
      "source": [
        "loss, accurary = model_lstm.evaluate(teste, y_teste, batch_size=16)\n",
        "print('Test loss/accurary:', loss, accurary)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste[0]"
      ],
      "metadata": {
        "id": "pLTGBDbnb5kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste.shape"
      ],
      "metadata": {
        "id": "l2eG2SaqchuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCXg55GxwbGg"
      },
      "outputs": [],
      "source": [
        "i = 50000\n",
        "for i in range(100):\n",
        "    a = x_teste[i]\n",
        "    b = a.reshape(1, 1, 12)\n",
        "\n",
        "    # Make predictions on new data\n",
        "    prediction = model_lstm.predict(b)\n",
        "    #predicted_class = label_encoder.inverse_transform(prediction)[0]\n",
        "\n",
        "    np.round(prediction, decimals=1, out=prediction)\n",
        "    np.round(x_teste[i], decimals=1, out=x_teste[i])\n",
        "    #print(\"Value:\", newArray[i + start])\n",
        "    if (np.sum(y_teste[i]) > 0):\n",
        "      print(\"X [:\", x_teste[i])\n",
        "      print(\"Y [:\", y_teste[i])\n",
        "      print(\"PC:\", prediction)\n",
        "      print (i)\n",
        "    i = 1 + 1\n",
        "#PREDICTIONS WITH COLAB MODEL\n",
        "#prediction = model.predict(teste)\n",
        "#print(\"Predicted class:\", prediction)\n",
        "#print(\"Predicted class:\", predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmrX4Kzdc0T3",
        "outputId": "3c468fe8-622f-476e-f75c-750a4878ea26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 822ms/step\n",
            "Value    : [0.    0.363 0.313 0.    0.    0.31  0.393 0.    0.    0.244 0.247 0.   ]\n",
            "Predicted: [0.04 1.   0.02 0.04 0.   0.01 0.01 0.01 0.01 0.01 0.44 0.01]\n"
          ]
        }
      ],
      "source": [
        "teste_value = np.array([0., 0.363, 0.313, 0., 0., 0.31, 0.393, 0., 0., 0.244, 0.247, 0.])\n",
        "teste_value = teste_value.reshape(1, 1, 12)\n",
        "\n",
        "# Make predictions on new data\n",
        "prediction = model_lstm.predict(teste_value)\n",
        "np.round(prediction, decimals=2, out=prediction)\n",
        "\n",
        "print(\"Value    :\", teste_value[0][0])\n",
        "print(\"Predicted:\", prediction[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02BdeK0gJrOU"
      },
      "source": [
        "# **SAVE THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGOyK8rXJvmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "7d0a5249-f640-4945-b90c-feaa6b10b3ee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_lstm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ce4a239d378a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm_model_v22.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_lstm' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "model_lstm.save(os.path.join(\".\", 'lstm_model_v23.h5'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}