{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UAH Driveset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for one trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# datasets\\UAH-DRIVESET-v1\\D1\\20151110175712-16km-D1-NORMAL1-SECONDARY\n",
    "\n",
    "# Get the current directory path\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up two directories from the current directory\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir, os.pardir))\n",
    "\n",
    "dataset_dir = os.path.join(root_dir, 'datasets', 'UAH-DRIVESET-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Data (UAH-Driveset dataset)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensor labels found in http://www.robesafe.uah.es/personal/eduardo.romera/pdfs/Romera16itsc.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#****************************************************#\n",
    "# RAW ACCELEROMETER - 10Hz\n",
    "# 1) Timestamp (seconds)\n",
    "# 2) Boolean of system activated (1 if >50km/h)\n",
    "# 3) Acceleration in X (Gs)\n",
    "# 4) Acceleration in Y (Gs)\n",
    "# 5) Acceleration in Z (Gs)\n",
    "# 6) Acceleration in X filtered by KF (Gs)\n",
    "# 7) Acceleration in Y filtered by KF (Gs)\n",
    "# 8) Acceleration in Z filtered by KF (Gs)\n",
    "# 9) Roll (degrees)\n",
    "# 10) Pitch (degrees)\n",
    "# 11) Yaw (degrees)\n",
    "#****************************************************#\n",
    "folder_path = os.path.join(dataset_dir, 'D1', '20151110175712-16km-D1-NORMAL1-SECONDARY')\n",
    "\n",
    "accel_path = os.path.join(folder_path, 'RAW_ACCELEROMETERS.txt')\n",
    "gps_path = os.path.join(folder_path, 'RAW_GPS.txt')\n",
    "\n",
    "raw_accelerometer = pd.read_csv(accel_path, delim_whitespace=True, header=None)\n",
    "\n",
    "raw_accelerometer.columns = [\n",
    "                'Timestamp_Accel',\n",
    "                'SystemActivated',\n",
    "                'accelerometerXAxis',\n",
    "                'accelerometerYAxis',\n",
    "                'accelerometerZAxis',\n",
    "                'AccelX_KF',\n",
    "                'AccelY_KF',\n",
    "                'AccelZ_KF',\n",
    "                'gyroscopeXAxis',\n",
    "                'gyroscopeYAxis',\n",
    "                'gyroscopeZAxis'\n",
    "]\n",
    "\n",
    "\n",
    "#****************************************************#\n",
    "# RAW GPS - 1Hz\n",
    "# 1) Timestamp (seconds)\n",
    "# 2) Speed (km/h)\n",
    "# 3) Latitude coordinate (degrees)\n",
    "# 4) Longitude coordinate (degrees)\n",
    "# 5) Altitude (meters)\n",
    "# 6) Vertical accuracy (degrees)\n",
    "# 7) Horizontal accuracy (degrees)\n",
    "# 8) Course (degrees)\n",
    "# 9) Difcourse: course variation (degrees)\n",
    "# 10) Lanex dist state [internal val]\n",
    "# 11) Lanex history [internal val]\n",
    "\n",
    "# https://github.com/Eromera/uah_driveset_reader/blob/master/driveset_reader.py\n",
    "#  elif (i == 10):\n",
    "#             self.columnInfo.setText('Lanex dist state [internal val]')\n",
    "#          elif (i == 11):\n",
    "#             self.columnInfo.setText('Lanex history [internal val]')\n",
    "#****************************************************#\n",
    "raw_gps = pd.read_csv(gps_path, delim_whitespace=True, header=None)\n",
    "\n",
    "raw_gps.columns = [ 'Timestamp_GPS', \n",
    "                   'Speed', \n",
    "                   'latitude',\n",
    "                   'longitude',\n",
    "                   'Altitude',\n",
    "                   'VerticalAccuracy',\n",
    "                   'HorizontalAccuracy',\n",
    "                   'Course',\n",
    "                   'Difcourse',\n",
    "                   'LanexDistState',\n",
    "                   'LanexHistory',\n",
    "                   'dropcolumn']\n",
    "\n",
    "raw_gps = raw_gps.drop(columns=['LanexDistState', 'LanexHistory', 'dropcolumn'])\n",
    "\n",
    "\n",
    "# Create dataframes\n",
    "df_accel = raw_accelerometer.copy()\n",
    "df_gps = raw_gps.copy()\n",
    "\n",
    "print(df_accel.head())\n",
    "print(df_gps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sampling**\n",
    "#### Upsample the GPS data to 10Hz\n",
    "\n",
    "GPS data = 1Hz \\\n",
    "Accelerometer data = 10Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPS data = 1Hz\n",
    "# Accelerometer data = 10Hz\n",
    "\n",
    "# Upsample the GPS data to 10Hz\n",
    "df_gps_upsampled = df_gps.reindex(df_gps.index.repeat(10)).reset_index(drop=True)\n",
    "df_gps = df_gps_upsampled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Syncronize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the closest match between accelerometer and GPS timestamps\n",
    "min_timestamp_accel = df_accel['Timestamp_Accel'].min()\n",
    "min_timestamp_gps = df_gps['Timestamp_GPS'].min()\n",
    "\n",
    "# Determine how many rows to trim from each dataframe\n",
    "if min_timestamp_accel < min_timestamp_gps:\n",
    "    row_number_accel = df_accel['Timestamp_Accel'].sub(min_timestamp_gps).abs().idxmin()\n",
    "    df_accel = df_accel.iloc[row_number_accel:]\n",
    "\n",
    "if min_timestamp_gps < min_timestamp_accel:\n",
    "    row_number_gps = df_gps['Timestamp_GPS'].sub(min_timestamp_accel).abs().idxmin()\n",
    "    df_gps = df_gps.iloc[row_number_gps:]\n",
    "\n",
    "# Ensure that both dataframes have the same length\n",
    "min_length = min(len(df_accel), len(df_gps))\n",
    "df_accel = df_accel.iloc[:min_length]\n",
    "df_gps = df_gps.iloc[:min_length]\n",
    "\n",
    "# Combine the dataframes\n",
    "df_combined = pd.concat([df_accel.reset_index(drop=True), df_gps.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save the synchronized data to CSV\n",
    "df_combined.to_csv('synchronized_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accelerometer data columns\n",
    "# timestamp = df_accel['Timestamp']\n",
    "# system_activated = df_accel['SystemActivated']\n",
    "# accelX = df_accel['AccelX']\n",
    "# accelY = df_accel['AccelY']\n",
    "# accelZ = df_accel['AccelZ']\n",
    "# accelX_KF = df_accel['AccelX_KF']\n",
    "# accelY_KF = df_accel['AccelY_KF']\n",
    "# accelZ_KF = df_accel['AccelZ_KF']\n",
    "# gyrX_roll = df_accel['Roll']\n",
    "# gyrY_pitch = df_accel['Pitch']\n",
    "# gyrZ_yaw = df_accel['Yaw']\n",
    "\n",
    "# # GPS data columns\n",
    "# timestamp_gps = df_gps['Timestamp']\n",
    "# speed = df_gps['Speed']\n",
    "# latitude = df_gps['Latitude']\n",
    "# longitude = df_gps['Longitude']\n",
    "# altitude = df_gps['Altitude']\n",
    "# vertical_accuracy = df_gps['VerticalAccuracy']\n",
    "# horizontal_accuracy = df_gps['HorizontalAccuracy']\n",
    "# course = df_gps['Course']\n",
    "# difcourse = df_gps['Difcourse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized code for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get the current directory path\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up two directories from the current directory\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir, os.pardir))\n",
    "\n",
    "dataset_dir = os.path.join(root_dir, 'datasets', 'UAH-DRIVESET-v1')\n",
    "output_dir = os.path.join(dataset_dir, 'UAH-Processed')\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Iterate through each subfolder in the dataset directory\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for subfolder in dirs:\n",
    "        subfolder_path = os.path.join(root, subfolder)\n",
    "\n",
    "        # Construct paths to accelerometer and GPS files\n",
    "        accel_path = os.path.join(subfolder_path, 'RAW_ACCELEROMETERS.txt')\n",
    "        gps_path = os.path.join(subfolder_path, 'RAW_GPS.txt')\n",
    "\n",
    "        # Check if both accelerometer and GPS files exist\n",
    "        if os.path.exists(accel_path) and os.path.exists(gps_path):\n",
    "            # Read raw accelerometer and GPS data\n",
    "            raw_accelerometer = pd.read_csv(accel_path, delim_whitespace=True, header=None)\n",
    "            raw_gps = pd.read_csv(gps_path, delim_whitespace=True, header=None)\n",
    "\n",
    "            # Preprocess and synchronize the data\n",
    "            raw_accelerometer.columns = [\n",
    "                'Timestamp_Accel',\n",
    "                'SystemActivated',\n",
    "                'accelerometerXAxis',\n",
    "                'accelerometerYAxis',\n",
    "                'accelerometerZAxis',\n",
    "                'AccelX_KF',\n",
    "                'AccelY_KF',\n",
    "                'AccelZ_KF',\n",
    "                'gyroscopeXAxis',\n",
    "                'gyroscopeYAxis',\n",
    "                'gyroscopeZAxis'\n",
    "            ]\n",
    "\n",
    "            raw_gps.columns = ['Timestamp_GPS',\n",
    "                               'Speed',\n",
    "                               'latitude',\n",
    "                               'longitude',\n",
    "                               'Altitude',\n",
    "                               'VerticalAccuracy',\n",
    "                               'HorizontalAccuracy',\n",
    "                               'Course',\n",
    "                               'Difcourse',\n",
    "                               'LanexDistState',\n",
    "                               'LanexHistory',\n",
    "                               'dropcolumn']\n",
    "\n",
    "            raw_gps = raw_gps.drop(columns=['LanexDistState', 'LanexHistory', 'dropcolumn'])\n",
    "\n",
    "            df_accel = raw_accelerometer.copy()\n",
    "            df_gps = raw_gps.copy()\n",
    "\n",
    "            df_gps_upsampled = df_gps.reindex(df_gps.index.repeat(10)).reset_index(drop=True)\n",
    "            df_gps = df_gps_upsampled.copy()\n",
    "\n",
    "            # Find the closest match between accelerometer and GPS timestamps\n",
    "            min_timestamp_accel = df_accel['Timestamp_Accel'].min()\n",
    "            min_timestamp_gps = df_gps['Timestamp_GPS'].min()\n",
    "\n",
    "            # Determine how many rows to trim from each dataframe\n",
    "            if min_timestamp_accel < min_timestamp_gps:\n",
    "                row_number_accel = df_accel['Timestamp_Accel'].sub(min_timestamp_gps).abs().idxmin()\n",
    "                df_accel = df_accel.iloc[row_number_accel:]\n",
    "            elif min_timestamp_gps < min_timestamp_accel:\n",
    "                row_number_gps = df_gps['Timestamp_GPS'].sub(min_timestamp_accel).abs().idxmin()\n",
    "                df_gps = df_gps.iloc[row_number_gps:]\n",
    "\n",
    "            # Ensure that both dataframes have the same length\n",
    "            min_length = min(len(df_accel), len(df_gps))\n",
    "            df_accel = df_accel.iloc[:min_length]\n",
    "            df_gps = df_gps.iloc[:min_length]\n",
    "\n",
    "            # Combine the dataframes\n",
    "            df_combined = pd.concat([df_accel.reset_index(drop=True), df_gps.reset_index(drop=True)], axis=1)\n",
    "\n",
    "            # Save the synchronized data to a CSV file with the same name as the subfolder\n",
    "            output_filename = os.path.join(output_dir, f'{subfolder}.csv')\n",
    "            df_combined.to_csv(output_filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
